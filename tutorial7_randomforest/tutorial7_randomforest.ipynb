{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "this notebook is prepared by kevin zhu for SYDE 522.\n",
        "\n",
        "references used:\n",
        "- https://towardsdatascience.com/building-a-random-forest-classifier-c73a4cae6781\n",
        "- Murphy 2022, Probabilistic Machine Learning: An Introduction\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Titanic dataset\n",
        "\n",
        "https://www.kaggle.com/competitions/titanic/data\n",
        "\n",
        "- survived:\tSurvived?\t\n",
        "    - 0 = No, 1 = Yes\n",
        "\n",
        "- pclass:\tTicket class\n",
        "\t- 1 = 1st, 2 = 2nd, 3 = 3rd\n",
        "- sex:\tSex\t\n",
        "    - male, female\n",
        "- age:\tAge in years\t\n",
        "- sibsp:\t# of siblings / spouses aboard the Titanic\t\n",
        "- parch:\t# of parents / children aboard the Titanic\t\n",
        "- fare:\tPassenger fare\t\n",
        "- embark_town:\tPort of Embarkation\t\n",
        "    - C = Cherbourg, Q = Queenstown, S = Southampton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset size: (712, 8)\n",
            "Overview:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>pclass</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>embark_town</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>Southampton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>Cherbourg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>Southampton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>Southampton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>Southampton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>male</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>51.8625</td>\n",
              "      <td>Southampton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>21.0750</td>\n",
              "      <td>Southampton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>11.1333</td>\n",
              "      <td>Southampton</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>female</td>\n",
              "      <td>14.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>30.0708</td>\n",
              "      <td>Cherbourg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>16.7000</td>\n",
              "      <td>Southampton</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    survived  pclass     sex   age  sibsp  parch     fare  embark_town\n",
              "0          0       3    male  22.0      1      0   7.2500  Southampton\n",
              "1          1       1  female  38.0      1      0  71.2833    Cherbourg\n",
              "2          1       3  female  26.0      0      0   7.9250  Southampton\n",
              "3          1       1  female  35.0      1      0  53.1000  Southampton\n",
              "4          0       3    male  35.0      0      0   8.0500  Southampton\n",
              "6          0       1    male  54.0      0      0  51.8625  Southampton\n",
              "7          0       3    male   2.0      3      1  21.0750  Southampton\n",
              "8          1       3  female  27.0      0      2  11.1333  Southampton\n",
              "9          1       2  female  14.0      1      0  30.0708    Cherbourg\n",
              "10         1       3  female   4.0      1      1  16.7000  Southampton"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load data\n",
        "titanic = sns.load_dataset('titanic')\n",
        "\n",
        "Ycolumms = ['survived']\n",
        "Xcolumns= ['pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embark_town']\n",
        "\n",
        "titanic = titanic[Ycolumms + Xcolumns].dropna()\n",
        "\n",
        "print('Dataset size:', titanic.shape)\n",
        "print('Overview:')\n",
        "titanic.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prob survival for female = 75.3%\n",
            "Prob survival for non first class female = 65.3%\n"
          ]
        }
      ],
      "source": [
        "print('Prob survival for female = {:.1f}%'.format(\n",
        "    titanic['survived'][titanic['sex'] == 'female'].mean() * 100 \n",
        "    ))\n",
        "\n",
        "print('Prob survival for non first class female = {:.1f}%'.format(\n",
        "    titanic['survived'][(titanic['sex'] == 'female') &\n",
        "                        (titanic['pclass'] != 1)].mean() * 100 \n",
        "    ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prob survival for children under 15 = 57.7%\n",
            "Prob survival for children under 15 that are alone = 50.0%\n",
            "Number of children under 15 that are alone = 4\n"
          ]
        }
      ],
      "source": [
        "print('Prob survival for children under 15 = {:.1f}%'.format(\n",
        "    titanic['survived'][titanic['age'] < 15].mean() * 100 \n",
        "    ))\n",
        "\n",
        "print('Prob survival for children under 15 that are alone = {:.1f}%'.format(\n",
        "    titanic['survived'][(titanic['age'] < 15) &\n",
        "                        (titanic['sibsp'] + titanic['parch'] == 0)].mean() * 100 \n",
        "    ))\n",
        "\n",
        "print('Number of children under 15 that are alone = {}'.format(\n",
        "    len(titanic[(titanic['age'] < 15) &\n",
        "                (titanic['sibsp'] + titanic['parch'] == 0)])\n",
        "    ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Decision trees \n",
        "(binary)\n",
        "\n",
        "<div>\n",
        "<img src=\"images/tree.png\" width=\"700\"/>\n",
        "</div>\n",
        "\n",
        "*values in image differ from the Titanic dataset loaded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### How to determine split?\n",
        "\n",
        "*We have to decide which feature to split on, and at what level. How?*\n",
        "\n",
        "We will try every single feature and every single level, score each combination, and select the best..\n",
        "\n",
        "```\n",
        "for feature in all features:\n",
        "    for level in feature levels:\n",
        "        split data by level and evaluate how good the split is\n",
        "select the best split\n",
        "```\n",
        "---\n",
        "\n",
        "### How to evaluate split?\n",
        "\n",
        "<u>Gini Index</u>\n",
        "\n",
        "One commonly used metric is the Gini impurity score. \n",
        "Let $P_k$ be the percent of data that falls in class $k$, for $K$ total classes:\n",
        "$$\n",
        "\\text{Gini} = 1- \\sum_{k=1}^K P_k^2\n",
        "$$\n",
        "\n",
        "(we want a lower Gini index)\n",
        "\n",
        "---\n",
        "\n",
        "### Back to splitting algorithm:\n",
        "\n",
        "After splitting the data into groups, we compute the Gini score for each group, then take the weighted sum of all groups as the Gini score for the split.\n",
        "\n",
        "For example, if we split the below data by sex (female/male), we get a Gini score of 0.2.\n",
        "\n",
        "<div>\n",
        "<img src=\"images/gini.png\" width=\"700\"/>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gini score for split 0.20\n"
          ]
        }
      ],
      "source": [
        "from randomforest import find_gini\n",
        "\n",
        "x = np.array([1,1,1,1,1,2,2,2])\n",
        "y = np.array([1,1,1,1,0,0,0,0])\n",
        "\n",
        "# split by female (x=1) and male (x=2):\n",
        "group_female = np.where(x==1)[0]\n",
        "group_male = np.where(x==2)[0]\n",
        "\n",
        "\n",
        "split_gini = find_gini(group_female, group_male, y)\n",
        "\n",
        "print('gini score for split {:.2f}'.format(split_gini))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Next step?\n",
        "\n",
        "Repeat for the left and right children of the previous split...\n",
        "\n",
        "- when do we stop?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "Back to Titanic.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# some data processing...\n",
        "\n",
        "# convert categorical features to label encodings (or one hot encoding)\n",
        "titanic = titanic.replace({'sex': {'male':0, 'female':1},\n",
        "                           'embark_town': {'Cherbourg': 0, 'Queenstown':1, 'Southampton':2}})\n",
        "\n",
        "X = titanic[Xcolumns] #predictors\n",
        "y = titanic[Ycolumms].to_numpy() #response\n",
        "\n",
        "# split data into train test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check root of decision tree (first split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "n: 569; gini:[0.33325706]; split:0.0; var: sex"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from randomforest import DecisionTree, RandomForest\n",
        "\n",
        "# fit decision tree\n",
        "tree = DecisionTree(X_train, y_train, min_leaf=5)\n",
        "tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check Gini score of root using our function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gini score for split 0.333\n"
          ]
        }
      ],
      "source": [
        "# split training data by sex\n",
        "group_female = np.where(X_train['sex']==1)[0]\n",
        "group_male = np.where(X_train['sex']==0)[0]\n",
        "\n",
        "# compute Gini score for split\n",
        "split_gini = find_gini(group_female, group_male, y_train[:,0])\n",
        "\n",
        "print('gini score for split {:.3f}'.format(split_gini))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check children of root:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root_left n: 361; gini:[0.28214396]; split:1.0; var: pclass\n",
            "root_right n: 208; gini:[0.25880759]; split:2.0; var: pclass\n"
          ]
        }
      ],
      "source": [
        "print('root_left', tree.lhs)\n",
        "print('root_right', tree.rhs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### True or False:\n",
        "\n",
        "Decision trees\n",
        "- are easy to interpret.\n",
        "-  can easily handle mixed discrete and continuous inputs.\n",
        "-  are insensitive to monotone transformations of the inputs, so there is no need to standardize the data.\n",
        "- perform automatic variable selection.\n",
        "- are relatively robust to outliers.\n",
        "- can handle missing input features.\n",
        "\n",
        "---\n",
        "\n",
        "What are some potential issues with decision trees?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Random forest\n",
        "\n",
        "Decision trees are a high variance estimator (i.e. unstable, predictions might vary a lot if the training data is perturbed).\n",
        "\n",
        "A simple way to reduce variance is to average multiple models (<u>ensemble learning</u>).\n",
        "\n",
        "In this case, we can fit multiple trees and average them.\n",
        "\n",
        "---\n",
        "\n",
        "How do we build \"different\" trees? Randomforests applies the 2 techniques below to build multiple trees in parallel.\n",
        "\n",
        "#### 1) Bagging (bootstrap aggregating).\n",
        "\n",
        "**What:** We fit different base models to different randomly sampled versions of the data to encourage the different models to make diverse predictions.\n",
        "\n",
        "The datasets are sampled with replacement (bootstrap sampling).\n",
        "If we sample with replacement $N$ times from our dataset of size $N$, the probability an observation is not in our bootstrapped dataset is $(1-\\frac{1}{N})^N$.\n",
        "\\begin{align}\n",
        "    \\lim_{N\\rightarrow \\infty} (1-\\frac{1}{N})^N = e^{-1} \\approx \\frac{1}{3}\n",
        "\\end{align}\n",
        "\n",
        "The <u>OOB (out-of-bag)</u> samples are the $\\approx\\frac{1}{3}$ observations that were not selected to build a parcticular tree. We can use this as a \"test set\" to evalute the tree.\n",
        "\n",
        "(*Note: Bagging does not always improve performance. In particular, it relies on the base models being unstable estimators, so that omitting some of the data significantly changes the resulting model fit.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prediction accuracy: 0.77\n"
          ]
        }
      ],
      "source": [
        "# implementation from randomforest.py\n",
        "\n",
        "# using 10 trees\n",
        "rf = RandomForest( X_train, y_train, n_trees=10, min_leaf = 1)\n",
        "\n",
        "preds = rf.predict(X_test.to_numpy())\n",
        "\n",
        "# prediction accuracy\n",
        "print('prediction accuracy: {:.2f}'.format(metrics.accuracy_score(y_test, preds)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(sklearn) prediction accuracy: 0.75\n"
          ]
        }
      ],
      "source": [
        "# sklearn implementation:\n",
        "rf_sk = RandomForestClassifier(n_estimators=10, bootstrap=True, max_features=None, min_samples_leaf=1)\n",
        "\n",
        "rf_sk.fit(X_train, y_train[:,0])\n",
        "\n",
        "pred_scikit = rf_sk.predict(X_test)\n",
        "\n",
        "print('(sklearn) prediction accuracy: {:.2f}'.format(metrics.accuracy_score(y_test, pred_scikit)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(sklearn no baggging) prediction accuracy: 0.71\n"
          ]
        }
      ],
      "source": [
        "# without bootstrap sampling\n",
        "rf_sk = RandomForestClassifier(n_estimators=10, bootstrap=False, max_features=None, min_samples_leaf=1)\n",
        "\n",
        "rf_sk.fit(X_train, y_train[:,0])\n",
        "\n",
        "pred_scikit = rf_sk.predict(X_test)\n",
        "\n",
        "print('(sklearn no baggging) prediction accuracy: {:.2f}'.format(metrics.accuracy_score(y_test, pred_scikit)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2) Limit the number of features to consider when looking for the best split.\n",
        "\n",
        "For a dataset with $M$ total features, at each split, sample a subset of features (usually of size $\\sqrt{M}$) to consider instead of all $M$ features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(sklearn rf) prediction accuracy: 0.78\n"
          ]
        }
      ],
      "source": [
        "rf_sk = RandomForestClassifier(n_estimators=10, bootstrap=True, max_features='sqrt', min_samples_leaf=1) \n",
        "\n",
        "rf_sk.fit(X_train, y_train[:,0])\n",
        "\n",
        "pred_scikit = rf_sk.predict(X_test)\n",
        "\n",
        "print('(sklearn rf) prediction accuracy: {:.2f}'.format(metrics.accuracy_score(y_test, pred_scikit)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(sklearn rf, ntree = 50) prediction accuracy: 0.80\n"
          ]
        }
      ],
      "source": [
        "rf_sk = RandomForestClassifier(n_estimators=50, bootstrap=True, max_features='sqrt', min_samples_leaf=1) \n",
        "\n",
        "rf_sk.fit(X_train, y_train[:,0])\n",
        "\n",
        "pred_scikit = rf_sk.predict(X_test)\n",
        "\n",
        "print('(sklearn rf, ntree = 50) prediction accuracy: {:.2f}'.format(metrics.accuracy_score(y_test, pred_scikit)))"
      ]
    }
  ],
  "metadata": {
    "gist": {
      "data": {
        "description": "RF_Classifier_Titanic",
        "public": true
      },
      "id": ""
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
